{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Wamp1re-Ai/Chatterbox-TTS-Extended/blob/main/chatterbox_tts_extended_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# ðŸŽ§ Chatterbox TTS Extended - Google Colab Notebook\n",
    "\n",
    "This notebook allows you to run [Chatterbox TTS Extended](https://github.com/Wamp1re-Ai/Chatterbox-TTS-Extended) directly in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, we'll clone the repository and install the required dependencies using `uv` for faster installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Wamp1re-Ai/Chatterbox-TTS-Extended.git\n",
    "%cd Chatterbox-TTS-Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Install uv package manager for faster dependency installation\n",
    "!pip install uv\n",
    "\n",
    "# Install PyTorch and torchvision with compatible versions first\n",
    "!uv pip install torch==2.7.0 torchaudio==2.7.0 torchvision --index-url https://download.pytorch.org/whl/cu128\n",
    "\n",
    "# Install transformers with a compatible version\n",
    "!uv pip install transformers==4.46.3\n",
    "\n",
    "# Install other dependencies from requirements file\n",
    "!uv pip install -r requirements.txt\n",
    "\n",
    "# Install additional dependencies that might be needed\n",
    "!uv pip install nltk\n",
    "\n",
    "# Download NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Add the current directory to Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'chatterbox/src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage"
   },
   "source": [
    "## Usage\n",
    "\n",
    "Now let's use the Chatterbox TTS Extended to generate speech from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import nltk\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from chatterbox.src.chatterbox.tts import ChatterboxTTS\n",
    "    print(\"Successfully imported ChatterboxTTS\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import ChatterboxTTS: {e}\")\n",
    "    # Try alternative import paths\n",
    "    try:\n",
    "        from src.chatterbox.tts import ChatterboxTTS\n",
    "        print(\"Successfully imported ChatterboxTTS from src.chatterbox.tts\")\n",
    "    except ImportError as e2:\n",
    "        print(f\"Failed to import ChatterboxTTS from src.chatterbox.tts: {e2}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize-model"
   },
   "outputs": [],
   "source": [
    "# Select device: CUDA if available, else CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the Chatterbox TTS model\n",
    "try:\n",
    "    model = ChatterboxTTS.from_pretrained(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded on device: {getattr(model, 'device', 'unknown')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate-speech"
   },
   "outputs": [],
   "source": [
    "def generate_speech(text, exaggeration=0.5, temperature=0.8, cfg_weight=0.5):\n",
    "    \"\"\"\n",
    "    Generate speech from text using Chatterbox TTS Extended\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to convert to speech\n",
    "        exaggeration (float): Emotion exaggeration (0.0 to 2.0)\n",
    "        temperature (float): Sampling temperature (0.01 to 5.0)\n",
    "        cfg_weight (float): Classifier-free guidance weight (0.1 to 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (waveform, sample_rate)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            # Generate audio\n",
    "            wav = model.generate(\n",
    "                text,\n",
    "                exaggeration=min(exaggeration, 1.0),\n",
    "                temperature=temperature,\n",
    "                cfg_weight=cfg_weight,\n",
    "                apply_watermark=False\n",
    "            )\n",
    "        \n",
    "        return wav, model.sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating speech: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, welcome to Chatterbox TTS Extended running on Google Colab! This is a demonstration of text-to-speech synthesis.\"\n",
    "\n",
    "try:\n",
    "    wav, sr = generate_speech(text)\n",
    "    print(f\"Generated audio with shape: {wav.shape} and sample rate: {sr}\")\n",
    "    \n",
    "    # Save the audio\n",
    "    output_path = \"generated_speech.wav\"\n",
    "    torchaudio.save(output_path, wav, sr)\n",
    "    print(f\"Audio saved to: {output_path}\")\n",
    "    \n",
    "    # Play the audio\n",
    "    display(Audio(output_path, rate=sr))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to generate speech: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced-usage"
   },
   "source": [
    "## Advanced Usage\n",
    "\n",
    "You can customize the speech generation by adjusting various parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "advanced-generation"
   },
   "outputs": [],
   "source": [
    "# More emotional speech\n",
    "emotional_text = \"Wow, this is incredible! I can't believe how realistic this text-to-speech sounds!\"\n",
    "\n",
    "try:\n",
    "    wav_emotional, sr_emotional = generate_speech(emotional_text, exaggeration=1.5, temperature=0.9)\n",
    "    \n",
    "    output_path_emotional = \"generated_speech_emotional.wav\"\n",
    "    torchaudio.save(output_path_emotional, wav_emotional, sr_emotional)\n",
    "    print(\"Emotional speech generated!\")\n",
    "    display(Audio(output_path_emotional, rate=sr_emotional))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to generate emotional speech: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "monotone-generation"
   },
   "outputs": [],
   "source": [
    "# More monotone speech\n",
    "monotone_text = \"This is a monotone voice with low emotion and high CFG weight for more literal speech.\"\n",
    "\n",
    "try:\n",
    "    wav_monotone, sr_monotone = generate_speech(monotone_text, exaggeration=0.2, temperature=0.3, cfg_weight=0.8)\n",
    "    \n",
    "    output_path_monotone = \"generated_speech_monotone.wav\"\n",
    "    torchaudio.save(output_path_monotone, wav_monotone, sr_monotone)\n",
    "    print(\"Monotone speech generated!\")\n",
    "    display(Audio(output_path_monotone, rate=sr_monotone))\n",
    "except Exception as e:\n",
    "    print(f\"Failed to generate monotone speech: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter any issues:\n",
    "\n",
    "1. Make sure you're using a GPU runtime in Colab (Runtime â†’ Change runtime type â†’ GPU)\n",
    "2. If you get out-of-memory errors, try:\n",
    "   - Reducing the length of the input text\n",
    "   - Using a CPU runtime (slower but uses less memory)\n",
    "3. For best results, use clear, properly punctuated English text\n",
    "4. If you encounter import errors, try restarting the runtime (Runtime â†’ Restart runtime) and running the cells again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "You've successfully run Chatterbox TTS Extended in Google Colab! You can now generate high-quality speech from text with various emotional expressions and styles.\n",
    "\n",
    "For more information about the parameters and advanced usage, check out the [Chatterbox TTS Extended GitHub repository](https://github.com/Wamp1re-Ai/Chatterbox-TTS-Extended)."
   ]
  }
 ],
 "metadata": {
 "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}